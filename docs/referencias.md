# ğŸ§  Curso de Engenharia de Prompt para Servidores PÃºblicos

> **Autor:** Adriano Marabuco

# Recursos e ReferÃªncias

## ğŸ“š Aula 0 - InteligÃªncia Artificial

* **Foundation Models:** BOMMASANI, Rishi et al. *On the opportunities and risks of foundation models*. arXiv preprint, 2021.
    * ğŸ”— [Ler no arXiv](https://arxiv.org/abs/2108.07258)
* **Stochastic Parrots:** BENDER, Emily M. et al. *On the dangers of stochastic parrots: Can language models be too big?*. ACM FAccT, 2021.
    * ğŸ”— [Ler na ACM Digital Library](https://dl.acm.org/doi/10.1145/3442188.3445922)
* **Transfer Learning:** PAN, Sinno Jialin; YANG, Qiang. *A survey on transfer learning*. IEEE Transactions on knowledge and data engineering, 2009.
    * ğŸ”— [Ler no IEEE Xplore](https://ieeexplore.ieee.org/document/5288526)
* **Diffusion Models:** SOHL-DICKSTEIN, Jascha et al. *Deep unsupervised learning using nonequilibrium thermodynamics*. ICML, 2015.
    * ğŸ”— [Ler no arXiv](https://arxiv.org/abs/1503.03585)
* **Riscos e AlucinaÃ§Ãµes:** LI, Zihao. *The dark side of chatgpt: Legal and ethical challenges from stochastic parrots and hallucination*. arXiv preprint, 2023.
    * ğŸ”— [Ler no arXiv](https://arxiv.org/abs/2304.14347)
* **Janela de Contexto:** LIU, Nelson F. et al. *Lost in the middle: How language models use long contexts*. arXiv preprint, 2023.
    * ğŸ”— [Ler no arXiv](https://arxiv.org/abs/2307.03172)
* **Impacto Cognitivo:** KOSMYNA, Nataliya et al. *Your brain on ChatGPT: Accumulation of cognitive debt when using an AI assistant for essay writing task*. arXiv preprint, 2025.
    * ğŸ”— [Verificar no arXiv](https://arxiv.org/abs/2506.08872) *(Nota: Citado nos slides como material de 2025)*


## Aula 1 LGPD

## ğŸ“œ LegislaÃ§Ã£o e Guias TÃ©cnicos

Documentos oficiais e guias orientadores sobre a aplicaÃ§Ã£o da lei e o uso de IA.

* **Lei Geral de ProteÃ§Ã£o de Dados (LGPD):** Lei nÂº 13.709/2018.
    * *Artigos citados:* Art. 1Âº (Fundamentos), Art. 3Âº (AplicaÃ§Ã£o), Art. 5Âº (DefiniÃ§Ãµes), Art. 6Âº (PrincÃ­pios), Art. 42-43 (Responsabilidade), Art. 52 (SanÃ§Ãµes).
* **IA Generativa e a LGPD (ANPD):** Documento tÃ©cnico sobre o tratamento de dados pessoais em sistemas de IA.
    * ğŸ”— [Ler Radar TecnolÃ³gico ANPD (PDF)](https://www.gov.br/anpd/pt-br/centrais-de-conteudo/documentos-tecnicos-orientativos/radar_tecnologico_ia_generativa_anpd.pdf/view)
* **Cartilha de SeguranÃ§a (CERT.br):** FascÃ­culo sobre Vazamento de Dados.
    * ğŸ”— [Ler FascÃ­culo (PDF)](https://cartilha.cert.br/fasciculos/vazamento-de-dados/fasciculo-vazamento-de-dados.pdf)

## Aula 2 Engenharia de Prompts

## ğŸ“š ReferÃªncias BibliogrÃ¡ficas (Papers)

Artigos acadÃªmicos fundamentais que embasam as tÃ©cnicas de *Prompt Engineering* discutidas em aula.

* **Zero-Shot Learning:**
    * KOJIMA, Takeshi et al. *Large language models are zero-shot reasoners*. [cite_start]NeurIPS, 2022. [cite: 639]
    * LAROCHELLE, Hugo et al. *Zero-data learning of new tasks*. [cite_start]AAAI, 2008. [cite: 641]
* **Few-Shot Learning:**
    * BROWN, Tom et al. *Language models are few-shot learners*. [cite_start]NeurIPS, 2020. [cite: 662]
* **Instruction Following:**
    * OUYANG, Long et al. *Training language models to follow instructions with human feedback*. [cite_start]NeurIPS, 2022. [cite: 683]
* **Meta Prompting:**
    * REYNOLDS, Laria; MCDONELL, Kyle. *Prompt programming for large language models: Beyond the few-shot paradigm*. [cite_start]CHI, 2021. [cite: 703]
    * ZHOU, Yongchao et al. *Large language models are human-level prompt engineers*. [cite_start]ICLR, 2022. [cite: 705]
* **Chain of Thought (CoT):**
    * WEI, Jason et al. *Chain-of-thought prompting elicits reasoning in large language models*. [cite_start]NeurIPS, 2022. [cite: 714]
* **Self-Refine (ReflexÃ£o):**
    * MADAAN, Aman et al. *Self-refine: Iterative refinement with self-feedback*. [cite_start]NeurIPS, 2023. [cite: 724]
* **Role-Play:**
    * KONG, Aobo et al. [cite_start]*Better zero-shot reasoning with role-play prompting*. arXiv, 2023. [cite: 734]
* **RAG (Retrieval-Augmented Generation):**
    * LEWIS, Patrick et al. *Retrieval-augmented generation for knowledge-intensive nlp tasks*. [cite_start]NeurIPS, 2020. [cite: 742]
* **ReAct (Reason + Act):**
    * YAO, Shunyu et al. *React: Synergizing reasoning and acting in language models*. [cite_start]ICLR, 2022. [cite: 751]
* **Engenharia de IA:**
    * HUYEN, Chip. *AI Engineering: Building Applications with Foundation Models*. [cite_start]O'Reilly Media. [cite: 531]

## ğŸ“˜ Guias Oficiais e DocumentaÃ§Ã£o

Materiais tÃ©cnicos das principais desenvolvedoras de LLMs.

### Google (Gemini)
* **EstratÃ©gias de Prompting:** DocumentaÃ§Ã£o oficial da API do Gemini.
    * [cite_start]ğŸ”— [Ler DocumentaÃ§Ã£o](https://ai.google.dev/gemini-api/docs/prompting-strategies?hl=pt-br) [cite: 532]
* **Prompting Guide 101:** Guia para Google Workspace.
    * [cite_start]ğŸ”— [Baixar PDF](https://services.google.com/fh/files/misc/gemini-for-google-workspace-prompting-guide-101.pdf) [cite: 545]

### Anthropic (Claude)
* **Modelos e VariÃ¡veis:** Guia sobre templates de prompts.
    * [cite_start]ğŸ”— [Ler Guia](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/prompt-templates-and-variables) [cite: 555]
* **Chain of Thought:** Exemplos prÃ¡ticos.
    * [cite_start]ğŸ”— [Ver Exemplos](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/chain-of-thought#example-writing-donor-emails-guided-cot) [cite: 717]

### OpenAI
* **Prompt Engineering Guide:** Guia oficial de boas prÃ¡ticas.
    * [cite_start]ğŸ”— [Ler Guia](https://platform.openai.com/docs/guides/prompt-engineering) [cite: 569]

### Outros
* **Markdown Guide (GitHub):** Sintaxe para formataÃ§Ã£o de textos.
    * [cite_start]ğŸ”— [Acessar Guia](https://docs.github.com/pt/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax) [cite: 584]

## ğŸ—ƒï¸ RepositÃ³rios de Prompts

Bibliotecas de prompts prontos para uso e inspiraÃ§Ã£o.

* [cite_start]**Google Gallery:** [ai.google.dev/gemini-api/prompts](https://ai.google.dev/gemini-api/prompts?hl=pt-br) [cite: 622]
* [cite_start]**Anthropic Prompt Library:** [docs.claude.com/en/resources/prompt-library](https://docs.claude.com/en/resources/prompt-library/library) [cite: 624]
* [cite_start]**OpenAI Prompt Pack:** [academy.openai.com](https://academy.openai.com/public/clubs/work-users-ynjqu/resources/chatgpt-for-any-role) [cite: 623]
* [cite_start]**RepositÃ³rio Nacional (TCU/TCE):** [cines.tcerr.tc.br/appiagen](https://cines.tcerr.tc.br/appiagen/) [cite: 625]

## ğŸ“° Leituras Complementares

* **Artigo:** "ChatGPT cria ou destrÃ³i trabalho?" por Silvio Meira.
    * [cite_start]ğŸ”— [Ler artigo](https://silvio.meira.com/chatgpt-cria-ou-destroi-trabalho/) [cite: 511]

### Recursos e RepositÃ³rios

* **Galeria Google:**
    * [https://ai.google.dev/gemini-api/prompts?hl=pt-br](https://ai.google.dev/gemini-api/prompts?hl=pt-br) [cite: 115]
* **Prompt Pack OpenAI:**
    * [https://academy.openai.com/public/clubs/work-users-ynjqu/resources/chatgpt-for-any-role](https://academy.openai.com/public/clubs/work-users-ynjqu/resources/chatgpt-for-any-role) [cite: 116]
* **Prompt Library (Claude):**
    * [https://docs.claude.com/en/resources/prompt-library/library](https://docs.claude.com/en/resources/prompt-library/library) [cite: 117]
* **RepositÃ³rio Nacional de Prompts:**
    * [https://cines.tcerr.tc.br/appiagen/](https://cines.tcerr.tc.br/appiagen/) [cite: 118]
